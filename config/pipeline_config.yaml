# =============================================================================
# NL2ATL Verification Pipeline Configuration
# =============================================================================
# This file configures the multi-model cross-verification pipeline.
# Copy this file to config/pipeline_config.yaml and customize as needed.

# -----------------------------------------------------------------------------
# Generator Model Configuration
# Used for NL â†’ ATL translation in two-stage generation
# -----------------------------------------------------------------------------
generator:
  provider: openai           # Options: openai, anthropic, azure_openai, mock
  model_name: gpt-4o-mini    # Model identifier
  temperature: 0.2           # Low temp for precise ATL generation
  max_tokens: 512
  api_key_env: OPENAI_API_KEY  # Environment variable for API key

# -----------------------------------------------------------------------------
# Verifier Model Configuration  
# Different provider for cross-verification (prevents over-reliance)
# -----------------------------------------------------------------------------
verifier:
  provider: anthropic        # Using Claude for verification
  model_name: claude-sonnet-4-20250514
  temperature: 0.0           # Zero temp for consistent verification
  max_tokens: 512
  api_key_env: ANTHROPIC_API_KEY

# -----------------------------------------------------------------------------
# Temperature Strategy for Two-Stage Generation
# -----------------------------------------------------------------------------
temperatures:
  nl_generation: 0.9         # High temp: creative, diverse NL statements
  atl_translation: 0.2       # Low temp: precise, syntactically correct ATL
  verification: 0.0          # Zero temp: deterministic verification judgments

# -----------------------------------------------------------------------------
# Verification Thresholds
# -----------------------------------------------------------------------------
thresholds:
  confidence: 0.7            # Minimum confidence to mark as "verified"
  cross_model_agreement: true  # Require verifier's ATL to match generator's

# -----------------------------------------------------------------------------
# Retry Configuration
# -----------------------------------------------------------------------------
retry:
  max_retries: 3
  delay_seconds: 1.0         # Delay between retries (helps with rate limits)

# -----------------------------------------------------------------------------
# Output Configuration
# -----------------------------------------------------------------------------
output:
  report_dir: reports        # Directory for verification reports
  save_intermediate: true    # Save intermediate results for debugging

# -----------------------------------------------------------------------------
# Batch Processing
# -----------------------------------------------------------------------------
batch:
  size: 10                   # Process samples in batches of this size
  delay_between_batches: 0.5 # Seconds to wait between batches

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
logging:
  level: INFO                # DEBUG, INFO, WARNING, ERROR
  file: logs/pipeline.log    # Log file path (null for stdout only)
  format: "%(asctime)s [%(levelname)s] %(message)s"

# -----------------------------------------------------------------------------
# Model Fallback Configuration (if primary fails)
# -----------------------------------------------------------------------------
fallback:
  enabled: true
  generator_fallback:
    provider: anthropic
    model_name: claude-3-haiku-20240307
  verifier_fallback:
    provider: openai
    model_name: gpt-4o-mini
